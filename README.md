# Projet Credit Scoring - Home Credit Default Risk

## ğŸ“‹ Description

Projet de prÃ©diction du risque de dÃ©faut de paiement pour Home Credit. Ce projet utilise des techniques de machine learning pour prÃ©dire la probabilitÃ© qu'un client ne rembourse pas son crÃ©dit, avec un focus sur l'optimisation du coÃ»t mÃ©tier et l'interprÃ©tabilitÃ© des modÃ¨les.

## ğŸ—ï¸ Structure du projet

```
OC_P6/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # DonnÃ©es brutes (non versionnÃ©es)
â”‚   â”‚   â”œâ”€â”€ application_train.csv
â”‚   â”‚   â”œâ”€â”€ application_test.csv
â”‚   â”‚   â”œâ”€â”€ bureau.csv
â”‚   â”‚   â”œâ”€â”€ bureau_balance.csv
â”‚   â”‚   â”œâ”€â”€ credit_card_balance.csv
â”‚   â”‚   â”œâ”€â”€ installments_payments.csv
â”‚   â”‚   â”œâ”€â”€ POS_CASH_balance.csv
â”‚   â”‚   â””â”€â”€ previous_application.csv
â”‚   â””â”€â”€ processed/                    # Datasets prÃ©traitÃ©s (non versionnÃ©s)
â”‚       â”œâ”€â”€ features_full.csv
â”‚       â”œâ”€â”€ features_train.csv
â”‚       â””â”€â”€ features_test.csv
â”œâ”€â”€ notebooks/                        # Notebooks d'apprentissage
â”‚   â”œâ”€â”€ 01_exploration.ipynb         # EDA complÃ¨te
â”‚   â””â”€â”€ 02_preparation_features.ipynb # Feature Engineering
â”œâ”€â”€ src/                              # Code Python rÃ©utilisable
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ load_data.py              # Fonction de chargement des donnÃ©es
â”œâ”€â”€ projet/                           # Documents de mission
â”‚   â”œâ”€â”€ mission.txt
â”‚   â””â”€â”€ etapes.txt
â”œâ”€â”€ pyproject.toml                    # Configuration projet et dÃ©pendances (UV)
â”œâ”€â”€ .gitignore                        # ProtÃ¨ge les donnÃ©es
â”œâ”€â”€ README.md
â””â”€â”€ uv.lock                           # Lock des dÃ©pendances
```

## ğŸš€ Installation

Ce projet utilise **[UV](https://docs.astral.sh/uv/)** pour la gestion des dÃ©pendances.

### Installation avec UV (recommandÃ©)

```bash
# Installer UV si pas dÃ©jÃ  fait
curl -LsSf https://astral.sh/uv/install.sh | sh

# Synchroniser l'environnement et installer les dÃ©pendances
uv sync

# Activer l'environnement virtuel
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows
```

### Installer les dÃ©pendances de dÃ©veloppement

```bash
uv sync --extra dev
```

### Ajouter une nouvelle dÃ©pendance

```bash
uv add nom-du-package
```

## ğŸ“Š DonnÃ©es

Les donnÃ©es proviennent du concours Kaggle [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk).

TÃ©lÃ©chargez les fichiers suivants et placez-les dans `data/raw/`:
- `application_train.csv`
- `application_test.csv`
- `bureau.csv`
- `bureau_balance.csv`
- `credit_card_balance.csv`
- `installments_payments.csv`
- `POS_CASH_balance.csv`
- `previous_application.csv`

## ğŸ¯ Utilisation

### 1. Exploration des donnÃ©es

```bash
jupyter notebook notebooks/01_exploration.ipynb
```

**Contenu :**
- Chargement et premiÃ¨re inspection des donnÃ©es
- Analyse de la variable cible (dÃ©sÃ©quilibre des classes)
- Analyse des valeurs manquantes
- Exploration des corrÃ©lations
- DÃ©tection d'anomalies (DAYS_EMPLOYED = 365243)
- Analyse des variables EXT_SOURCE (prÃ©dicteurs clÃ©s)

### 2. PrÃ©paration des features (Feature Engineering)

```bash
jupyter notebook notebooks/02_preparation_features.ipynb
```

**Contenu :**
- Chargement et fusion de 7 tables de donnÃ©es
- Nettoyage des donnÃ©es (valeurs aberrantes, sentinelles)
- Encodage des variables catÃ©gorielles (One-Hot encoding)
- CrÃ©ation de features par agrÃ©gation (min, max, mean, sum, var)
- Features spÃ©cifiques :
  - Ratios et pourcentages (ex: INCOME_CREDIT_PERC, PAYMENT_RATE)
  - Comportement de paiement (DPD, DBD)
  - CrÃ©dits actifs vs fermÃ©s
  - Demandes approuvÃ©es vs refusÃ©es
- SÃ©paration train/test
- Sauvegarde des datasets prÃ©parÃ©s

**Output :** 
- `data/processed/features_full.csv` (~800+ features)
- `data/processed/features_train.csv`
- `data/processed/features_test.csv`

## ğŸ“ Approche

Ce projet suit l'approche du kernel Kaggle **"LightGBM with Simple Features"** de [jsaguiar](https://www.kaggle.com/jsaguiar), qui a obtenu d'excellents rÃ©sultats sur cette compÃ©tition.

**StratÃ©gie :**
- ModulabilitÃ© : une fonction pour chaque table de donnÃ©es
- AgrÃ©gations statistiques sur les donnÃ©es groupÃ©es
- CrÃ©ation de ratios et pourcentages entre variables importantes
- Features spÃ©cifiques pour diffÃ©rents profils (crÃ©dits actifs/fermÃ©s, demandes approuvÃ©es/refusÃ©es)

**Approche de modÃ©lisation prÃ©vue :**
1. Feature Selection : identifier les features les plus importantes
2. ModÃ©lisation : LightGBM avec validation croisÃ©e (K-Fold)
3. Optimisation : tuning des hyperparamÃ¨tres
4. Ã‰valuation : mÃ©triques (ROC-AUC, coÃ»ts mÃ©tier)
5. PrÃ©dictions : gÃ©nÃ©rer les prÃ©dictions pour le test set
## ğŸ¤ Contribution

Les contributions sont les bienvenues! Merci de:
1. CrÃ©er une branche pour votre feature
2. Respecter le style de code
3. Mettre Ã  jour la documentation

## ğŸ“„ Licence

Ce projet est Ã  usage Ã©ducatif.

## ğŸ“ Status d'apprentissage

**Phase actuelle :** Exploration et Feature Engineering  
**Prochaines phases :** ModÃ©lisation et Optimisation

Ce projet est conÃ§u comme un parcours d'apprentissage en machine learning appliquÃ© au credit scoring.