{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def425de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION DU NOTEBOOK\n",
    "# ============================================================================\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Configuration MLflow\n",
    "MLFLOW_TRACKING_URI = \"http://127.0.0.1:5000\"\n",
    "MLFLOW_EXPERIMENT_NAME = \"OC_P6_Credit_Scoring\"\n",
    "\n",
    "# Configuration du projet\n",
    "PROJECT_VERSION = \"1.0\"\n",
    "MODEL_NAME = \"LightGBM\"\n",
    "NOTEBOOK_NAME = \"03_LGBM\"\n",
    "RUN_DATE = datetime.datetime.now()\n",
    "\n",
    "# Configuration des donn√©es\n",
    "DATA_PATH = \"../data/processed/\"\n",
    "TRAIN_FILE = \"features_train.csv\"\n",
    "TEST_FILE = \"features_test.csv\"\n",
    "\n",
    "# Configuration du mod√®le baseline\n",
    "MODEL_CONFIG = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# Configuration de la validation\n",
    "VALIDATION_SPLIT_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Configuration des tags MLflow\n",
    "MLFLOW_TAGS = {\n",
    "    \"project_version\": PROJECT_VERSION,\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"phase\": \"baseline\",\n",
    "    \"desequilibre_handling\": \"class_weight_balanced\",\n",
    "    \"date\": RUN_DATE,\n",
    "}\n",
    "\n",
    "print(\"Configuration charg√©e avec succ√®s !\")\n",
    "print(f\"MLflow Experiment: {MLFLOW_EXPERIMENT_NAME}\")\n",
    "print(f\"Project Version: {PROJECT_VERSION}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc76b8",
   "metadata": {},
   "source": [
    "# 03 - LightGBM Modeling with MLflow Tracking\n",
    "\n",
    "Configuration and experimentation notebook for credit scoring model.\n",
    "All runs will be tracked in MLflow for comparison and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4647f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mlflow_config import configure_mlflow\n",
    "\n",
    "mlflow = configure_mlflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Exemple si tu as sauvegard√© les features\n",
    "X_train = pd.read_csv(\"../data/processed/features_train.csv\")\n",
    "y_train = X_train.pop(\"TARGET\")  # ou le nom de ta cible\n",
    "# M√™me chose pour X_val, y_val si tu as un split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cross-validation LightGBM + co√ªt m√©tier\n",
    "# ============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "# Nettoyage des colonnes avant entra√Ænement (noms + types)\n",
    "object_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "if object_cols:\n",
    "    for col in object_cols:\n",
    "        X_train[col] = pd.to_numeric(X_train[col], errors='coerce').fillna(0)\n",
    "X_train.columns = (\n",
    "    X_train.columns\n",
    "    .str.replace(' ', '_')\n",
    "    .str.replace('[^a-zA-Z0-9_]', '_', regex=True)\n",
    "    .str.replace('__+', '_', regex=True)\n",
    ")\n",
    "\n",
    "# Param√®tres mod√®le (assurer class_weight=balanced)\n",
    "MODEL_CONFIG_CV = {**MODEL_CONFIG, \"class_weight\": \"balanced\"}\n",
    "\n",
    "# K-Fold stratifi√©\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "thresholds = np.round(np.arange(0.1, 0.91, 0.05), 2)\n",
    "\n",
    "RUN_NAME_CV = \"LGBM_baseline_CV\"\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME_CV):\n",
    "    # Log param√®tres\n",
    "    mlflow.log_params(MODEL_CONFIG_CV)\n",
    "    \n",
    "    # Log tags existants\n",
    "    for tag_key, tag_value in MLFLOW_TAGS.items():\n",
    "        mlflow.set_tag(tag_key, tag_value)\n",
    "    mlflow.set_tag(\"model_type\", MODEL_NAME)\n",
    "    mlflow.set_tag(\"phase\", \"baseline_cv\")\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), start=1):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = LGBMClassifier(**MODEL_CONFIG_CV)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_val_proba)\n",
    "        \n",
    "        best_threshold = None\n",
    "        min_cost = None\n",
    "        best_fp = None\n",
    "        best_fn = None\n",
    "        \n",
    "        for thr in thresholds:\n",
    "            y_val_pred = (y_val_proba >= thr).astype(int)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred).ravel()\n",
    "            cost = 10 * fn + 1 * fp\n",
    "            if (min_cost is None) or (cost < min_cost):\n",
    "                min_cost = cost\n",
    "                best_threshold = thr\n",
    "                best_fp = fp\n",
    "                best_fn = fn\n",
    "        \n",
    "        fold_results.append({\n",
    "            \"fold\": fold_idx,\n",
    "            \"auc\": auc,\n",
    "            \"best_threshold\": best_threshold,\n",
    "            \"min_cost\": min_cost,\n",
    "            \"fp\": best_fp,\n",
    "            \"fn\": best_fn\n",
    "        })\n",
    "    \n",
    "    cv_results_df = pd.DataFrame(fold_results)\n",
    "    cv_auc_mean = cv_results_df[\"auc\"].mean()\n",
    "    cv_min_cost_mean = cv_results_df[\"min_cost\"].mean()\n",
    "    cv_best_threshold_mean = cv_results_df[\"best_threshold\"].mean()\n",
    "    \n",
    "    # Log m√©triques moyennes\n",
    "    mlflow.log_metric(\"cv_auc_mean\", cv_auc_mean)\n",
    "    mlflow.log_metric(\"cv_min_cost_mean\", cv_min_cost_mean)\n",
    "    mlflow.log_metric(\"cv_best_threshold_mean\", cv_best_threshold_mean)\n",
    "    \n",
    "    # Log artefact JSON\n",
    "    mlflow.log_dict(cv_results_df.to_dict(orient=\"records\"), \"cv_results.json\")\n",
    "    \n",
    "    print(\"‚úì Cross-validation termin√©e\")\n",
    "    print(f\"AUC moyen: {cv_auc_mean:.4f}\")\n",
    "    print(f\"Co√ªt m√©tier moyen: {cv_min_cost_mean:.2f}\")\n",
    "    print(f\"Seuil optimal moyen: {cv_best_threshold_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Optimisation RAPIDE Optuna (~10 min max)\n",
    "# ============================================================================\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "# Seuils grossiers pour vitesse\n",
    "thresholds = np.arange(0.2, 0.8, 0.1)  # 6 valeurs au lieu de ~20\n",
    "\n",
    "# CV acc√©l√©r√©e : 3 folds\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 128),         # plage r√©duite\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 12),            # -1 = no limit\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.03, 0.1, log=True),\n",
    "        \"n_estimators\": 800,                                            # fixe haut + early stopping\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 20, 80),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"random_state\": 42,\n",
    "        \"early_stopping_rounds\": 50,                                    # arr√™t pr√©coce\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "    \n",
    "    fold_costs = []\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        \n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "        min_cost, _ = compute_min_cost_per_fold(y_val, y_val_proba, thresholds)\n",
    "        fold_costs.append(min_cost)\n",
    "        \n",
    "        # Pruning manuel possible ici si besoin\n",
    "        trial.report(np.mean(fold_costs), step=len(fold_costs)-1)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return -np.mean(fold_costs)\n",
    "\n",
    "# Lancement dans run parent (UI propre)\n",
    "with mlflow.start_run(run_name=\"LGBM_optuna_rapide\", nested=True):\n",
    "    pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "    study.optimize(objective, n_trials=15, timeout=600)  # 10 min max s√©curit√©\n",
    "\n",
    "# ... (garde ton code post-optimisation : best_params, √©valuation CV, run final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ad490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION FINALE : Validation & Optimisation du seuil m√©tier (Hold-out)\n",
    "# ============================================================================\n",
    "# WHY HOLD-OUT :\n",
    "# - Valide la g√©n√©ralisation (√©vite overfitting de la CV)\n",
    "# - √âvalue le mod√®le sur donn√©es jamais vues pendant Optuna\n",
    "# - Refl√®te mieux la performance en production\n",
    "#\n",
    "# WHY SEUIL FIN ICI (pas dans Optuna) :\n",
    "# - Optuna avec seuils grossiers (0.2-0.7, step 0.1) : ~10 min, peu de pr√©cision\n",
    "# - Seuil fin (0.05-0.95, step 0.01) : ici rapidement sans ralentir optimisation\n",
    "#\n",
    "# WHY NESTED RUNS :\n",
    "# - Groupe parent \"LGBM_final_validation\" contient tous les r√©sultats\n",
    "# - UI MLflow propre (arborescence avec parent/enfants)\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Cr√©er le hold-out stratifi√© (20% test, 80% train)\n",
    "X_train_final, X_holdout, y_train_final, y_holdout = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2, \n",
    "    stratify=y_train, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"üîÄ Hold-out split:\")\n",
    "print(f\"   Train: {X_train_final.shape[0]} | Hold-out: {X_holdout.shape[0]}\")\n",
    "\n",
    "# 2. Utiliser best_params d'Optuna (ou valeurs par d√©faut si besoin)\n",
    "best_params = {\n",
    "    'num_leaves': 90,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.034964706548010455,\n",
    "    'n_estimators': 206,\n",
    "    'min_child_samples': 99,\n",
    "    'subsample': 0.6916174727904909,\n",
    "    'colsample_bytree': 0.8928138662796579,\n",
    "    'class_weight': 'balanced',\n",
    "    'early_stopping_rounds': 50\n",
    "}\n",
    "\n",
    "# 3. Entra√Æner le mod√®le final sur 80%\n",
    "print(\"\\nüöÄ Entra√Ænement du mod√®le final...\")\n",
    "final_model = LGBMClassifier(**best_params)\n",
    "\n",
    "# eval_set pour early_stopping\n",
    "final_model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    eval_set=[(X_holdout, y_holdout)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        plt.figure(),  # Ne pas afficher les logs\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"‚úì Mod√®le final entra√Æn√©\")\n",
    "\n",
    "# 4. Pr√©dire probabilit√©s sur hold-out\n",
    "y_holdout_proba = final_model.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "# 5. Calculer AUC-ROC sur hold-out\n",
    "holdout_auc = roc_auc_score(y_holdout, y_holdout_proba)\n",
    "print(f\"\\nüìä Hold-out AUC-ROC: {holdout_auc:.4f}\")\n",
    "\n",
    "# 6. Optimisation FINE du seuil (0.05-0.95, step 0.01)\n",
    "fine_thresholds = np.arange(0.05, 0.96, 0.01)\n",
    "threshold_costs = []\n",
    "\n",
    "for thr in fine_thresholds:\n",
    "    y_holdout_pred = (y_holdout_proba >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_holdout, y_holdout_pred).ravel()\n",
    "    cost = 10 * fn + 1 * fp\n",
    "    threshold_costs.append({\n",
    "        'threshold': thr,\n",
    "        'cost': cost,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tn': tn\n",
    "    })\n",
    "\n",
    "threshold_costs_df = pd.DataFrame(threshold_costs)\n",
    "optimal_idx = threshold_costs_df['cost'].idxmin()\n",
    "optimal_threshold = threshold_costs_df.loc[optimal_idx, 'threshold']\n",
    "min_cost = threshold_costs_df.loc[optimal_idx, 'cost']\n",
    "\n",
    "print(f\"üéØ Seuil optimal : {optimal_threshold:.2f}\")\n",
    "print(f\"üí∞ Co√ªt minimal : {min_cost:.2f}\")\n",
    "\n",
    "# 7. Calculer F1 et Recall au seuil optimal\n",
    "y_holdout_optimal = (y_holdout_proba >= optimal_threshold).astype(int)\n",
    "holdout_f1 = f1_score(y_holdout, y_holdout_optimal)\n",
    "holdout_recall = recall_score(y_holdout, y_holdout_optimal)\n",
    "\n",
    "print(f\"üìà F1-score (seuil optimal) : {holdout_f1:.4f}\")\n",
    "print(f\"üìà Recall classe 1 (seuil optimal) : {holdout_recall:.4f}\")\n",
    "\n",
    "# 8. Tracer la courbe co√ªt vs seuil\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(threshold_costs_df['threshold'], threshold_costs_df['cost'], \n",
    "         marker='o', linewidth=2, markersize=4)\n",
    "plt.axvline(optimal_threshold, color='red', linestyle='--', \n",
    "            label=f'Optimal = {optimal_threshold:.2f}')\n",
    "plt.xlabel('Seuil de d√©cision')\n",
    "plt.ylabel('Co√ªt m√©tier (10*FN + 1*FP)')\n",
    "plt.title('Courbe de co√ªt vs seuil (Hold-out)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Sauvegarder le plot\n",
    "plot_path = '/home/valentin/Env_Python/OC_P6/threshold_cost_curve.png'\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nüìä Plot sauvegard√© : {plot_path}\")\n",
    "\n",
    "# 9. Cr√©er run parent NESTED pour MLflow\n",
    "run_name_final = \"LGBM_final_validation\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name_final, nested=False) as parent_run:\n",
    "    # Log params\n",
    "    mlflow.log_params(best_params)\n",
    "    \n",
    "    # Log tags\n",
    "    for tag_key, tag_value in MLFLOW_TAGS.items():\n",
    "        mlflow.set_tag(tag_key, tag_value)\n",
    "    mlflow.set_tag(\"model_type\", MODEL_NAME)\n",
    "    mlflow.set_tag(\"phase\", \"final_validation\")\n",
    "    mlflow.set_tag(\"validation_method\", \"hold-out_20pct\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"holdout_auc\", holdout_auc)\n",
    "    mlflow.log_metric(\"holdout_min_cost\", min_cost)\n",
    "    mlflow.log_metric(\"optimal_threshold\", optimal_threshold)\n",
    "    mlflow.log_metric(\"holdout_f1\", holdout_f1)\n",
    "    mlflow.log_metric(\"holdout_recall\", holdout_recall)\n",
    "    \n",
    "    # Log plot\n",
    "    mlflow.log_artifact(plot_path)\n",
    "    \n",
    "    # Log tableau des co√ªts par d√©cile (JSON)\n",
    "    decile_costs = threshold_costs_df[::10].to_dict(orient='records')\n",
    "    mlflow.log_dict(decile_costs, \"threshold_costs_deciles.json\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Run MLflow parent : {parent_run.info.run_name}\")\n",
    "    print(f\"   üìä M√©triques : AUC={holdout_auc:.4f}, Min Cost={min_cost:.2f}, F1={holdout_f1:.4f}\")\n",
    "    print(f\"   üéØ Seuil optimal : {optimal_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb408ea",
   "metadata": {},
   "source": [
    "## Interpr√©tabilit√© (global + local) avec SHAP\n",
    "SHAP est pertinent pour la transparence m√©tier car il fournit une attribution **coh√©rente et locale** des contributions de chaque variable √† une d√©cision, tout en restant **agr√©geable au niveau global**. Cela permet d‚Äôexpliquer un score client individuel (force plot) et de justifier les facteurs principaux √† l‚Äô√©chelle du portefeuille (summary plot), ce qui est attendu en contexte de scoring de cr√©dit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d1e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Mod√®le final + Feature importance + SHAP\n",
    "# ============================================================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "# Entra√Æner le mod√®le final sur tout le train set\n",
    "final_model = LGBMClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "with mlflow.start_run(run_name=\"LGBM_final_interpretability\"):\n",
    "    # Tags + params\n",
    "    mlflow.log_params(best_params)\n",
    "    for tag_key, tag_value in MLFLOW_TAGS.items():\n",
    "        mlflow.set_tag(tag_key, tag_value)\n",
    "    mlflow.set_tag(\"model_type\", MODEL_NAME)\n",
    "    mlflow.set_tag(\"phase\", \"final_interpretability\")\n",
    "    \n",
    "    # Log du mod√®le final\n",
    "    mlflow.lightgbm.log_model(final_model, MODEL_NAME)\n",
    "    \n",
    "    # --- Feature importance globale (gain) ---\n",
    "    fig_gain, ax_gain = plt.subplots(figsize=(8, 6))\n",
    "    lgb.plot_importance(final_model, importance_type=\"gain\", ax=ax_gain, max_num_features=30)\n",
    "    ax_gain.set_title(\"Feature Importance (Gain)\")\n",
    "    mlflow.log_figure(fig_gain, \"feature_importance_gain.png\")\n",
    "    plt.close(fig_gain)\n",
    "    \n",
    "    # --- Feature importance globale (split) ---\n",
    "    fig_split, ax_split = plt.subplots(figsize=(8, 6))\n",
    "    lgb.plot_importance(final_model, importance_type=\"split\", ax=ax_split, max_num_features=30)\n",
    "    ax_split.set_title(\"Feature Importance (Split)\")\n",
    "    mlflow.log_figure(fig_split, \"feature_importance_split.png\")\n",
    "    plt.close(fig_split)\n",
    "    \n",
    "    # --- SHAP : interpr√©tabilit√© locale & globale ---\n",
    "    sample_size = min(1000, len(X_train))\n",
    "    X_sample = X_train.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    explainer = shap.TreeExplainer(final_model)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    \n",
    "    # Pour binaire, shap_values peut √™tre une liste [classe0, classe1]\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values_to_use = shap_values[1]\n",
    "    else:\n",
    "        shap_values_to_use = shap_values\n",
    "    \n",
    "    # Summary plot (bee swarm)\n",
    "    shap.summary_plot(shap_values_to_use, X_sample, show=False)\n",
    "    fig_summary = plt.gcf()\n",
    "    fig_summary.set_size_inches(10, 6)\n",
    "    mlflow.log_figure(fig_summary, \"shap_summary_beeswarm.png\")\n",
    "    plt.close(fig_summary)\n",
    "    \n",
    "    # Force plots pour 5 clients al√©atoires\n",
    "    force_dir = Path(\"shap_force_plots\")\n",
    "    force_dir.mkdir(parents=True, exist_ok=True)\n",
    "    rng = np.random.default_rng(42)\n",
    "    sample_indices = rng.choice(X_sample.index, size=min(5, len(X_sample)), replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices, start=1):\n",
    "        force_plot = shap.force_plot(explainer.expected_value if not isinstance(explainer.expected_value, (list, tuple)) else explainer.expected_value[1],\n",
    "                                     shap_values_to_use[X_sample.index.get_loc(idx)],\n",
    "                                     X_sample.loc[idx],\n",
    "                                     matplotlib=False)\n",
    "        force_path = force_dir / f\"shap_force_plot_{i}.html\"\n",
    "        shap.save_html(str(force_path), force_plot)\n",
    "        mlflow.log_artifact(str(force_path))\n",
    "    \n",
    "    print(\"‚úì Mod√®le final et artefacts d'interpr√©tabilit√© logg√©s dans MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes object en types num√©riques\n",
    "import numpy as np\n",
    "\n",
    "# Identifier et convertir les colonnes object\n",
    "object_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Colonnes object d√©tect√©es: {object_cols}\")\n",
    "\n",
    "# Convertir chaque colonne object en numeric\n",
    "for col in object_cols:\n",
    "    X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
    "    # Remplacer les NaN introduits par la conversion par 0\n",
    "    X_train[col] = X_train[col].fillna(0)\n",
    "\n",
    "# Nettoyer les noms de colonnes (remplacer les caract√®res sp√©ciaux)\n",
    "X_train.columns = X_train.columns.str.replace(' ', '_').str.replace('[^a-zA-Z0-9_]', '_', regex=True)\n",
    "\n",
    "# V√©rifier que toutes les colonnes sont num√©riques\n",
    "print(f\"Dtypes apr√®s conversion:\\n{X_train.dtypes.value_counts()}\")\n",
    "print(f\"\\nColonnes (exemples): {X_train.columns[:5].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16afb8",
   "metadata": {},
   "source": [
    "## Runs de mod√®les\n",
    "Les entra√Ænements et le logging MLflow commencent ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split si pas d√©j√† fait\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=VALIDATION_SPLIT_RATIO, \n",
    "    stratify=y_train, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Appliquer les m√™mes transformations aux donn√©es splitt√©es\n",
    "X_train_split.columns = X_train_split.columns.str.replace(' ', '_').str.replace('[^a-zA-Z0-9_]', '_', regex=True)\n",
    "X_val_split.columns = X_val_split.columns.str.replace(' ', '_').str.replace('[^a-zA-Z0-9_]', '_', regex=True)\n",
    "\n",
    "# Nom du run avec version\n",
    "RUN_NAME = f\"{MODEL_NAME}_baseline_{PROJECT_VERSION}\"\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME):\n",
    "    \n",
    "    # D√©finition du mod√®le avec la configuration\n",
    "    model = LGBMClassifier(**MODEL_CONFIG)\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # Pr√©dictions et m√©triques\n",
    "    y_pred_proba = model.predict_proba(X_val_split)[:, 1]\n",
    "    y_pred = model.predict(X_val_split)\n",
    "    \n",
    "    auc = roc_auc_score(y_val_split, y_pred_proba)\n",
    "    f1 = f1_score(y_val_split, y_pred)\n",
    "    recall_1 = recall_score(y_val_split, y_pred)\n",
    "    \n",
    "    # === TRACKING MLFlow ===\n",
    "    # Appliquer les tags depuis la configuration\n",
    "    for tag_key, tag_value in MLFLOW_TAGS.items():\n",
    "        mlflow.set_tag(tag_key, tag_value)\n",
    "    \n",
    "    # Ajouter des tags suppl√©mentaires\n",
    "    mlflow.set_tag(\"model_type\", MODEL_NAME)\n",
    "    \n",
    "    # M√©triques principales\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"recall_class_1\", recall_1)\n",
    "    \n",
    "    # Artefacts utiles (ex: plot importance)\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # ... plot feature importance ...\n",
    "    # plt.savefig(\"feature_importance.png\")\n",
    "    # mlflow.log_artifact(\"feature_importance.png\")\n",
    "    \n",
    "    # Log du mod√®le avec le nom depuis la configuration\n",
    "    mlflow.lightgbm.log_model(model, MODEL_NAME)\n",
    "    \n",
    "    print(f\"‚úì Run termin√©: {RUN_NAME}\")\n",
    "    print(f\"  AUC: {auc:.4f} | F1: {f1:.4f} | Recall_1: {recall_1:.4f}\")\n",
    "    print(f\"  Tags appliqu√©s: {MLFLOW_TAGS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5c225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OC_P6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
